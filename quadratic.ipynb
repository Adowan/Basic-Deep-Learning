{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSPq-JJFbUde",
        "outputId": "841ee72c-cbde-41a2-98ac-0e75edfec2b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at gdrive\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('gdrive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df= pd.read_csv(\"gdrive/MyDrive/Colab Notebooks/quadratic/data/train.csv\")\n",
        "np.random.shuffle(train_df.values)\n",
        "print(train_df.head(5))\n",
        "#Define layers> first-hidden layers (with input dimension or layers),output layers\n",
        "model= keras.Sequential([\n",
        "    keras.layers.Dense(32, input_shape=(2,), activation='relu'),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(2,activation='sigmoid')])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits= True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "x=np.column_stack((train_df.x.values, train_df.y.values))\n",
        "model.fit(x,train_df.color.values, batch_size=4, epochs=10)\n",
        "\n",
        "\n",
        "test_df=pd.read_csv(\"gdrive/MyDrive/Colab Notebooks/quadratic/data/test.csv\")\n",
        "test_x= np.column_stack((test_df.x.values, test_df.y.values))\n",
        "print(\"Evaluation follows here:\")\n",
        "model.evaluate(test_x, test_df.color.values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aY-zdWU7bh3R",
        "outputId": "08c2a13d-4532-40c0-9f98-13cface5dfa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          x          y  color\n",
            "0  3.090229   7.852402    1.0\n",
            "1 -4.389253  21.019558    0.0\n",
            "2 -2.129964   6.210904    0.0\n",
            "3  4.024341  14.804060    1.0\n",
            "4  3.805045  13.064564    1.0\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4982 - accuracy: 0.7450\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2749 - accuracy: 0.9020\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1713 - accuracy: 0.9427\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1057 - accuracy: 0.9707\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0667 - accuracy: 0.9855\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0577 - accuracy: 0.9852\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0519 - accuracy: 0.9845\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0302 - accuracy: 0.9930\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0430 - accuracy: 0.9875\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0317 - accuracy: 0.9940\n",
            "Evaluation follows here:\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0137 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.013742776587605476, 1.0]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}